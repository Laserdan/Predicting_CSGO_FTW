{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Supervised ML regression algorithm to predict next round team value (CT & T)**\n",
    "## **Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_df = pd.read_csv('../data/processed/4_base_predict_next_rnd_ct_type.csv')\n",
    "t_df = pd.read_csv('../data/processed/4_base_predict_next_rnd_t_type.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a manual encoding to be sure of being the same values for round_type and nxt_rnd_type.\n",
    "\n",
    "If we use LabelEncoder() it could be possible to have different values for the same label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_type_dic = {'PISTOL_ROUND':0, 'ECO':1, 'MEDIUM':2, 'FULL':3, 'LAST':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_df['round_type'] = ct_df['round_type'].apply(lambda x: round_type_dic[x])\n",
    "ct_df['nxt_rnd_type'] = ct_df['nxt_rnd_type'].apply(lambda x: round_type_dic[x])\n",
    "\n",
    "t_df['round_type'] = t_df['round_type'].apply(lambda x: round_type_dic[x])\n",
    "t_df['nxt_rnd_type'] = t_df['nxt_rnd_type'].apply(lambda x: round_type_dic[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_FEATS = ['file', 'round', 'wp_ct_val', 'nade_ct_val', 'ct_alive', 't_alive', 'ct_winner', 'bomb_planted', 'ct_cons_wins', 't_cons_wins', 'ct_val_pred', 'round_type']\n",
    "T_FEATS = ['file', 'round', 'wp_t_val', 'nade_t_val', 'ct_alive', 't_alive', 'ct_winner', 'bomb_planted', 'ct_cons_wins', 't_cons_wins', 't_val_pred', 'round_type']\n",
    "TARGET = 'nxt_rnd_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessor\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "preprocessor_ct = ColumnTransformer(transformers=[('num', numeric_transformer, CT_FEATS)])\n",
    "preprocessor_t = ColumnTransformer(transformers=[('num', numeric_transformer, T_FEATS)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the most accurate classifier algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithm | Accuracy Score |\n",
    "|----------|---------------|\n",
    "| SGDClassifier | 0.5366519098115927 |\n",
    "| RandomForestClassifier | 0.5304102748893236 |\n",
    "| LinearSVC | 0.5668691444455883 |\n",
    "| LogisticRegression | 0.5623648718212705 |\n",
    "| SVC | Too slow, not finished |\n",
    "| KNeighborsClassifier | 0.5497271697724699 |\n",
    "| <font color='green'>LGBMClassifier</font> | <font color='green'>0.644432719036343</font> |\n",
    "| GradientBoostingClassifier | 0.644432719036343 |\n",
    "| AdaBoostClassifier | 0.5766241120148254 |\n",
    "| ExtraTreesClassifier | 0.6142669618037682 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the analysis we will use **LGBMClassifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search to hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 25.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('t_preprocessor',\n",
       "                                              ColumnTransformer(transformers=[('num',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['file',\n",
       "                                                                                'round',\n",
       "                                                                                'wp_t_val',\n",
       "                                                                                'nade_t_val',\n",
       "                                                                                'ct_alive',\n",
       "                                                                                't_alive',\n",
       "                                                                                'ct_winner',\n",
       "                                                                                'bomb_planted',\n",
       "                                                                                'ct_cons_wins',\n",
       "                                                                                't_cons_wins',\n",
       "                                                                                't_val_pred',\n",
       "                                                                                'round_type'])])),\n",
       "                                             ('regressor', LGBMClassifier())]),\n",
       "                   n_iter=20, n_jobs...\n",
       "                                                                         0.9,\n",
       "                                                                         0.95,\n",
       "                                                                         1],\n",
       "                                        'regressor__feature_fraction': [0.75,\n",
       "                                                                        0.8,\n",
       "                                                                        0.85,\n",
       "                                                                        0.9,\n",
       "                                                                        0.95,\n",
       "                                                                        1],\n",
       "                                        'regressor__learning_rate': [0.02, 0.03,\n",
       "                                                                     0.04,\n",
       "                                                                     0.045,\n",
       "                                                                     0.05,\n",
       "                                                                     0.055,\n",
       "                                                                     0.06],\n",
       "                                        'regressor__max_depth': [5, 6, 7],\n",
       "                                        'regressor__min_data_in_leaf': [4, 5, 6,\n",
       "                                                                        7, 8,\n",
       "                                                                        12,\n",
       "                                                                        15],\n",
       "                                        'regressor__n_estimators': [350, 360,\n",
       "                                                                    370, 380,\n",
       "                                                                    390, 400,\n",
       "                                                                    410, 420,\n",
       "                                                                    430],\n",
       "                                        'regressor__num_leaves': [47, 48, 49,\n",
       "                                                                  50, 51, 52]},\n",
       "                   scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(t_df[T_FEATS], t_df[TARGET])\n",
    "\n",
    "\n",
    "# To obtain the best hyperparameters of our model, we test a wider range of values and then \n",
    "# we reduce until obtaining close but different values, in order to obtain the best results.\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__num_leaves': [47,48,49,50,51,52],\n",
    "    'regressor__n_estimators': [350,360,370,380,390,400,410,420,430],\n",
    "    'regressor__min_data_in_leaf': [4,5,6,7,8,12,15],\n",
    "    'regressor__max_depth': [5,6,7],\n",
    "    'regressor__learning_rate': [0.02,0.03,0.04,0.045,0.05,0.055,0.06],\n",
    "    'regressor__feature_fraction': [0.75,0.8,0.85,0.9,0.95,1],\n",
    "    'regressor__bagging_frequency': [0.75,0.80,0.85,0.9,0.95,1],\n",
    "    'regressor__bagging_fraction': [0.75,0.8,0.85,0.9,0.95,1],\n",
    "}\n",
    "\n",
    "\n",
    "regressor = LGBMClassifier()  # better without this (boosting_type='rf', bagging_freq=1, bagging_fraction = 0.9, n_estimators=100)\n",
    "\n",
    "model = Pipeline(steps=[('t_preprocessor', preprocessor_t),\n",
    "                           ('regressor', regressor)])\n",
    "\n",
    "# MODEL --------------------------------------\n",
    "\n",
    "grid_search = RandomizedSearchCV(model, \n",
    "                                 param_grid, \n",
    "                                 cv=5, \n",
    "                                 verbose=5, \n",
    "                                 scoring='accuracy', \n",
    "                                 n_jobs=-1,\n",
    "                                 n_iter=20)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# model.fit(X_train, y_train);\n",
    "\n",
    "\n",
    "# sk_report = classification_report(\n",
    "#     digits=6,\n",
    "#     y_true=y_test, \n",
    "#     y_pred=model.predict(X_test))\n",
    "# print(sk_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor__num_leaves': 47,\n",
       " 'regressor__n_estimators': 430,\n",
       " 'regressor__min_data_in_leaf': 4,\n",
       " 'regressor__max_depth': 6,\n",
       " 'regressor__learning_rate': 0.06,\n",
       " 'regressor__feature_fraction': 0.75,\n",
       " 'regressor__bagging_frequency': 0.8,\n",
       " 'regressor__bagging_fraction': 0.75}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Once we have trained the model with different hyperparameter values, \n",
    "#we see which parameters have obtained the best score:\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6397736653621884"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the best score that we have trained:\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different values obtained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameter | Value |\n",
    "|----------|---------------|\n",
    "| regressor__num_leaves | 48 |\n",
    "| regressor__n_estimators | 430 |\n",
    "| regressor__min_data_in_leaf | 7 |\n",
    "| regressor__max_depth | 7 |\n",
    "| regressor__learning_rate | 0.055 |\n",
    "| regressor__feature_fraction | 0.75 |\n",
    "| regressor__bagging_frequency | 1 |\n",
    "| regressor__bagging_fraction | 1 |\n",
    "| RESULT | 0.6447327118410268 |\n",
    "\n",
    "\n",
    "| Parameter | Value |\n",
    "|----------|---------------|\n",
    "| regressor__num_leaves | 48 |\n",
    "| regressor__n_estimators | 420 |\n",
    "| regressor__min_data_in_leaf | 5 |\n",
    "| regressor__max_depth | 6 |\n",
    "| regressor__learning_rate | 0.06 |\n",
    "| regressor__feature_fraction | 0.8 |\n",
    "| regressor__bagging_frequency | 0.8 |\n",
    "| regressor__bagging_fraction | 0.75 |\n",
    "| RESULT | 0.6444796262481058 |\n",
    "\n",
    "\n",
    "| Parameter | Value |\n",
    "|----------|---------------|\n",
    "| regressor__num_leaves | 48 |\n",
    "| regressor__n_estimators | 410 |\n",
    "| regressor__min_data_in_leaf | 5 |\n",
    "| regressor__max_depth | 7 |\n",
    "| regressor__learning_rate | 0.05 |\n",
    "| regressor__feature_fraction | 0.75 |\n",
    "| regressor__bagging_frequency | 0.75 |\n",
    "| regressor__bagging_fraction | 0.75 |\n",
    "| RESULT | 0.6445010686323108 |\n",
    "\n",
    "\n",
    "    \n",
    "| Parameter | Value |\n",
    "|----------|---------------|\n",
    "| regressor__num_leaves | 50 |\n",
    "| regressor__n_estimators | 350 |\n",
    "| regressor__min_data_in_leaf | 15 |\n",
    "| regressor__max_depth | 7 |\n",
    "| regressor__learning_rate | 0.055 |\n",
    "| regressor__feature_fraction | 0.8 |\n",
    "| regressor__bagging_frequency | 0.75 |\n",
    "| regressor__bagging_fraction | 0.75 |\n",
    "| <font color='green'> **RESULT** </font>  | <font color='green'> **0.6456121568307236** </font>  |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ironhack_env]",
   "language": "python",
   "name": "conda-env-ironhack_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
