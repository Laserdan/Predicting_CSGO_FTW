{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Supervised ML regression algorithm to predict next round team value (CT & T)**\n",
    "## **Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_df = pd.read_csv('../data/processed/4_base_predict_next_rnd_ct_type.csv')\n",
    "t_df = pd.read_csv('../data/processed/4_base_predict_next_rnd_t_type.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a manual encoding to be sure of being the same values for round_type and nxt_rnd_type.\n",
    "\n",
    "If we use LabelEncoder() it could be possible to have different values for the same label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_type_dic = {'PISTOL_ROUND':0, 'ECO':1, 'MEDIUM':2, 'FULL':3, 'LAST':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_df['round_type'] = ct_df['round_type'].apply(lambda x: round_type_dic[x])\n",
    "ct_df['nxt_rnd_type'] = ct_df['nxt_rnd_type'].apply(lambda x: round_type_dic[x])\n",
    "\n",
    "t_df['round_type'] = t_df['round_type'].apply(lambda x: round_type_dic[x])\n",
    "t_df['nxt_rnd_type'] = t_df['nxt_rnd_type'].apply(lambda x: round_type_dic[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_FEATS = ['file', 'round', 'wp_ct_val', 'nade_ct_val', 'ct_alive', 't_alive', 'ct_winner', 'bomb_planted', 'ct_cons_wins', 't_cons_wins', 'ct_val_pred', 'round_type']\n",
    "T_FEATS = ['file', 'round', 'wp_t_val', 'nade_t_val', 'ct_alive', 't_alive', 'ct_winner', 'bomb_planted', 'ct_cons_wins', 't_cons_wins', 't_val_pred', 'round_type']\n",
    "TARGET = 'nxt_rnd_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessor\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "preprocessor_ct = ColumnTransformer(transformers=[('num', numeric_transformer, CT_FEATS)])\n",
    "preprocessor_t = ColumnTransformer(transformers=[('num', numeric_transformer, T_FEATS)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beggining of stackoverflow solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=5000, n_features=5,\n",
    "                           n_informative=5, n_redundant=0,\n",
    "                           n_classes=5, random_state=0, \n",
    "                           shuffle=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ct_df[CT_FEATS], ct_df[TARGET])\n",
    "\n",
    "# regressor = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# regressor = SGDClassifier(early_stopping=True, loss='hinge')\n",
    "# regressor = LinearSVC()\n",
    "# regressor = LogisticRegression()\n",
    "regressor = SVC(gamma='auto', probability=True)\n",
    "# regressor = KNeighborsClassifier()\n",
    "# regressor = LGBMClassifier()  # better without this (boosting_type='rf', bagging_freq=1, bagging_fraction = 0.9, n_estimators=100)\n",
    "# regressor = GradientBoostingClassifier(n_estimators=100) # Same as LGBM but one-thread processing, too slow\n",
    "# regressor = AdaBoostClassifier(n_estimators=100)\n",
    "# regressor = ExtraTreesClassifier(n_estimators=100)\n",
    "\n",
    "# model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# model = SGDClassifier(early_stopping=True, loss='hinge')\n",
    "\n",
    "model = Pipeline(steps=[('ct_preprocessor', preprocessor_ct),\n",
    "                           ('regressor', regressor)])\n",
    "\n",
    "model.fit(X_train, y_train);\n",
    "\n",
    "\n",
    "# sk_report = classification_report(\n",
    "#     digits=6,\n",
    "#     y_true=y_test, \n",
    "#     y_pred=model.predict(X_test))\n",
    "# print(sk_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5623648718212705"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithm | Score |\n",
    "|----------|---------------|\n",
    "| SGDClassifier | 0.5366519098115927 |\n",
    "| RandomForestClassifier | 0.5304102748893236 |\n",
    "| LinearSVC | 0.5668691444455883 |\n",
    "| LogisticRegression | 0.5623648718212705 |\n",
    "| SVC | 000 |\n",
    "| KNeighborsClassifier | 0.5497271697724699 |\n",
    "| LGBMClassifier | 0.644432719036343 |\n",
    "| GradientBoostingClassifier | 0.644432719036343 |\n",
    "| AdaBoostClassifier | 0.5766241120148254 |\n",
    "| ExtraTreesClassifier | 0.6142669618037682 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### average = 'macro'\n",
    "\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "               0   0.047330  0.032713  0.038687      3332\n",
    "               1   0.145251  0.001603  0.003170     16224\n",
    "               2   0.383403  0.056582  0.098611     14616\n",
    "               3   0.539235  0.968083  0.692653     40511\n",
    "               4   0.017857  0.001986  0.003575      3021\n",
    "\n",
    "        accuracy                       0.517168     77704\n",
    "        macro avg  0.226615  0.212193  0.167339     77704\n",
    "        weighted avg 0.386299  0.517168  0.382123     77704\n",
    "\n",
    "\n",
    "-----\n",
    "#### average = 'micro'  original code\n",
    "\n",
    "\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "               0   0.000000  0.000000  0.000000      3305\n",
    "               1   0.225766  0.932514  0.363522     16359\n",
    "               2   0.166667  0.000068  0.000136     14655\n",
    "               3   0.673026  0.157701  0.255528     40266\n",
    "               4   0.017316  0.003847  0.006296      3119\n",
    "\n",
    "        accuracy                       0.278210     77704\n",
    "       macro avg   0.216555  0.218826  0.125096     77704\n",
    "    weighted avg   0.428419  0.278210  0.209224     77704\n",
    "\n",
    "---- \n",
    "#### average = 'micro' not original code\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0   0.000000  0.000000  0.000000      3399\n",
    "           1   0.000000  0.000000  0.000000     16312\n",
    "           2   0.187268  0.994156  0.315168     14546\n",
    "           3   0.723992  0.008447  0.016698     40371\n",
    "           4   0.000000  0.000000  0.000000      3076\n",
    "\n",
    "    accuracy                       0.190492     77704\n",
    "    macro avg   0.182252  0.200521  0.066373     77704\n",
    "    weighted avg   0.411205  0.190492  0.067674     77704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SPLITS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_train, ct_test = train_test_split(ct_df)\n",
    "t_train, t_test = train_test_split(t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233109, 13) (77704, 13)\n",
      "(233109, 13) (77704, 13)\n"
     ]
    }
   ],
   "source": [
    "print(ct_train.shape, ct_test.shape)\n",
    "print(t_train.shape, t_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor = LGBMRegressor(boosting_type='gbdt', \n",
    "#                        bagging_freq=1, \n",
    "#                        bagging_fraction = 0.9, \n",
    "#                        n_estimators=100)\n",
    "\n",
    "regressor = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_model = Pipeline(steps=[('ct_preprocessor', preprocessor_ct),\n",
    "                           ('regressor', regressor)])\n",
    "\n",
    "# t_model = Pipeline(steps=[('t_preprocessor', preprocessor_t),\n",
    "#                            ('regressor', regressor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_model.fit(ct_train[CT_FEATS], ct_train[TARGET]);\n",
    "\n",
    "# t_model.fit(t_train[T_FEATS], t_train[TARGET]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ct_test = ct_model.predict_proba(ct_test[CT_FEATS])[:,1]\n",
    "y_ct_train = ct_model.predict_proba(ct_train[CT_FEATS])[:,1]\n",
    "\n",
    "# y_ct_test = ct_model.predict(ct_test[CT_FEATS])\n",
    "# y_ct_train = ct_model.predict(ct_train[CT_FEATS])\n",
    "\n",
    "# y_t_test = t_model.predict(t_test[T_FEATS])\n",
    "# y_t_train = t_model.predict(t_train[T_FEATS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CHECK PERFORMANCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "print(f\"CT test error: {roc_auc_score(ct_test[TARGET].to_numpy(), y_ct_test, average = 'macro', multi_class='ovr')}\")\n",
    "print(f\"CT train error: {roc_auc_score(ct_train[TARGET].to_numpy(), y_ct_train, average = 'macro', multi_class='ovr')}\")\n",
    "print()\n",
    "# print(f\"T test error: {roc_auc_score(y_pred=y_t_test, y_true=t_test[T_TARGET])}\")\n",
    "# print(f\"T train error: {roc_auc_score(y_pred=y_t_train, y_true=t_train[T_TARGET])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ironhack_env]",
   "language": "python",
   "name": "conda-env-ironhack_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
